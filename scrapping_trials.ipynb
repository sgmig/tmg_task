{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separate-integrity",
   "metadata": {},
   "source": [
    "#  Web scrapping for NLP task.\n",
    "\n",
    "The goal of this notebook is to build a tool that can scrape text from a given list of websites, in order to use it later for clustering the sites. \n",
    "\n",
    "The task indicates that we should get text from the landing page, as well as text from the links contained in the landing page. \n",
    "\n",
    "Since many requests will be necessary, some mechanism has to be put in place in order to avoid being blocked. \n",
    "(user-agents, proxy, etc.)\n",
    "\n",
    "As each page contains many links, parallel processing can be implemented in order to speed up the scrapping. \n",
    "\n",
    "The final product should be able to take a list of websites and build text files with the contents of each site. \n",
    "Additional parameters could be included for managing, for instance, the pareallel processing, or maybe some further filtering of the contents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-diving",
   "metadata": {},
   "source": [
    "##  Scrapping from one site\n",
    "\n",
    "Let's use one of the given URLs to get an idea of the kind of websites we have. \n",
    "\n",
    "For example, this british pipe supplier: http://www.besseges-vtf.co.uk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "digital-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "recreational-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header():\n",
    "    \"\"\"\n",
    "    Returns a random header dictionary to be passed to requests. \n",
    "    \"\"\"\n",
    "\n",
    "    # Headers for user agent rotation:\n",
    "    # Full headers obtained from hhttpbin.org\n",
    "    # Firefox 84 Ubuntu\n",
    "\n",
    "\n",
    "    h1 =  {\n",
    "        \"Accept\": \t\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Encoding\":\t\"gzip, deflate, br\",\n",
    "        \"Accept-Language\":\t\"en-US,en;q=0.5\",\n",
    "        \"Connection\":\t\"keep-alive\",\n",
    "        \"Host\":\t\"httpbin.org\",\n",
    "        \"TE\":\t\"Trailers\",\n",
    "        \"Upgrade-Insecure-Requests\":\t\"1\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:84.0) Gecko/20100101 Firefox/84.0\"\n",
    "      }\n",
    "\n",
    "    #Firefox 84 Windows 10\n",
    "\n",
    "    h2 = {\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\", \n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\", \n",
    "        \"Accept-Language\": \"en-GB,en;q=0.5\", \n",
    "        \"Host\": \"httpbin.org\", \n",
    "        \"Upgrade-Insecure-Requests\": \"1\", \n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:84.0) Gecko/20100101 Firefox/84.0\"\n",
    "       }\n",
    "\n",
    "    # Chrome 87 Ubuntu\n",
    "\n",
    "    h3 = {\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\", \n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,fr;q=0.8,es;q=0.7\", \n",
    "        \"Host\": \"httpbin.org\", \n",
    "        \"Sec-Fetch-Dest\": \"document\", \n",
    "        \"Sec-Fetch-Mode\": \"navigate\", \n",
    "        \"Sec-Fetch-Site\": \"none\", \n",
    "        \"Sec-Fetch-User\": \"?1\", \n",
    "        \"Upgrade-Insecure-Requests\": \"1\", \n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\", \n",
    "      }\n",
    "\n",
    "    #Chrome 87 Windows 10\n",
    "\n",
    "    h4 = {\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "        \"Accept-Encoding\": \"gzip, deflate\", \n",
    "        \"Accept-Language\": \"es-419,es;q=0.9,fr;q=0.8,en;q=0.7\", \n",
    "        \"Host\": \"httpbin.org\", \n",
    "        \"Upgrade-Insecure-Requests\": \"1\", \n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36\"\n",
    "      }\n",
    "\n",
    "    # Microsoft Edge 87 Windows 10\n",
    "\n",
    "    h5 = {\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\", \n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\", \n",
    "        \"Host\": \"httpbin.org\", \n",
    "        \"Sec-Fetch-Dest\": \"document\", \n",
    "        \"Sec-Fetch-Mode\": \"navigate\", \n",
    "        \"Sec-Fetch-Site\": \"none\", \n",
    "        \"Sec-Fetch-User\": \"?1\", \n",
    "        \"Upgrade-Insecure-Requests\": \"1\", \n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 Edg/87.0.664.75\"\n",
    "      }\n",
    "\n",
    "    headers_list = [h1, h2, h3, h4, h5]\n",
    "    \n",
    "    return random.choice(headers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "judicial-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(soup, tags = 'a'):\n",
    "    \"\"\" Get get all the links for the given tags from a parsed page.  \n",
    "    soup: an html page parsed with beautifulsoup.\n",
    "    tags: string or list of strings indicating the html tags to search. \n",
    "    \"\"\"\n",
    "    \n",
    "    links = [] # list to store the links found\n",
    "    \n",
    "    for tag in tags:\n",
    "        for link in soup.find_all(tag, href=True):\n",
    "            links.append(link['href'])\n",
    "           \n",
    "    links = list(set(links))\n",
    "        \n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "twelve-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_links(home, links_list):\n",
    "    \"\"\"\n",
    "    Takes a home address and a list of links, and filters out links to external sites\n",
    "    and to some common file types.\n",
    "    home: string. The URL of the home page.\n",
    "    links_list: list of strings with the links found on the page, as produced by get_links.\n",
    "    \"\"\"\n",
    "    \n",
    "    domain = urlparse(home).netloc # domain to to check for external links.\n",
    "    \n",
    "    # path to include before an internal link. Remove final '/' if present.\n",
    "    path = home[:-1] if home.endswith('/') else home \n",
    "\n",
    "    unwanted_starts = ('javascript:', 'mailto:', 'tel:', '#', '..', '../') \n",
    "    \n",
    "    unwanted_endings = ('.pdf', '.jpg', '.jpeg', '.png', '.gif', '.exe', '.js',\n",
    "                        '.zip', '.tar', '.gz', '.7z', '.rar'\n",
    "                       )\n",
    "    \n",
    "    filtered_links = list(filter(lambda link: not (link.lower().startswith(unwanted_starts) or \n",
    "                                                   link.lower().endswith(unwanted_endings)),links_list\n",
    "                                )\n",
    "                         )\n",
    "    \n",
    "    # get internal links that don't have the full URL\n",
    "    internal_links = [link for link in filtered_links if not link.startswith('http') ]\n",
    "\n",
    "    # Ensure starting '/'  \n",
    "    for j, intlink in enumerate(internal_links):\n",
    "        if not intlink.startswith('/'):\n",
    "            internal_links[j]='/'+intlink\n",
    "            \n",
    "    internal_links = [path + intlink for intlink in internal_links]\n",
    "    \n",
    "    # removing external links\n",
    "    filtered_links = list(filter(lambda link: (link.lower().startswith('http') and\n",
    "                                                domain in link.lower()), filtered_links\n",
    "                                )\n",
    "                         )\n",
    "    \n",
    "    # include internal links\n",
    "    filtered_links.extend(internal_links)\n",
    "    \n",
    "    # keeping disntinct elements only\n",
    "    \n",
    "    filtered_links = list(set(filtered_links))\n",
    "    \n",
    "    # remove home url if present.    \n",
    "    try:\n",
    "        filtered_links.remove(path)\n",
    "    except(ValueError):\n",
    "        pass\n",
    "    try:\n",
    "        filtered_links.remove(path+'/')\n",
    "    except(ValueError):\n",
    "        pass\n",
    "        \n",
    "    return filtered_links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "toxic-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_page(page,file):\n",
    "    \"\"\" Gets the text of a page and appends it to the specified file.\n",
    "    File will be created if it does not exists. \n",
    "    page: a BeautifulSoup obeject with the parsed page.\n",
    "    file: string. Path to the destination file.\n",
    "     \"\"\"\n",
    "    \n",
    "    \n",
    "    page_text = page.get_text(separator = '\\n', strip=True) \n",
    "    \n",
    "    with open(file,'a') as website_text:\n",
    "        website_text.write(page_text)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-apparatus",
   "metadata": {},
   "source": [
    "Trial URLs\n",
    "\n",
    "    *'http://www.besseges-vtf.co.uk'\n",
    "    *'http://lumaquin.com'\n",
    "    *'https://www.degso.com'\n",
    "    *'http://www.ictsl.net'\n",
    "    *'https://barrocorestaurante.mx'\n",
    "    *'https://www.gummigoetz.de'\n",
    "    *'http://www.suppliersof.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "advanced-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set landing page URL\n",
    "\n",
    "MAIN_URL = 'http://www.ictsl.net'\n",
    "\n",
    "TEXTS_DIRECTORY = './site_contents/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instant-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request contents\n",
    "\n",
    "random_header = random.choice(headers_list)\n",
    "\n",
    "landing_page = requests.get(MAIN_URL, {'header': random_header})\n",
    "landing_html = BeautifulSoup(landing_page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "serious-april",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NewConnectionError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f131cdf87d0>: Failed to establish a new connection: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='www.estawebnoexiste.com.ar', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f131cdf87d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-76980bf408b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlanding_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyweb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNewConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_task/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='www.estawebnoexiste.com.ar', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f131cdf87d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-76980bf408b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlanding_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyweb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mexcept\u001b[0m \u001b[0mNewConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfailed_attempts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyweb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NewConnectionError' is not defined"
     ]
    }
   ],
   "source": [
    "#what happens with requests when a page doesn't exist?\n",
    "\n",
    "myweb = 'http://www.estawebnoexiste.com.ar'\n",
    "failed_attempts = []\n",
    "try:\n",
    "    landing_page = requests.get(myweb)\n",
    "except NewConnectionError:\n",
    "    failed_attempts.append(myweb)\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "human-editing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./site_contents/www.ictsl.net'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a file name for the website and write the text of the main page.\n",
    "file_name = FILES_DIRECTORY + urlparse(MAIN_URL).netloc\n",
    "\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "australian-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_page(file_name, landing_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = get_links(landing_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-helicopter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = filter_links(MAIN_URL, link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extended-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "corporate-chinese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "involved-catch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['website',\n",
       " 'http://lumaquin.com',\n",
       " 'https://www.degso.com',\n",
       " 'http://www.ictsl.net',\n",
       " 'https://barrocorestaurante.mx',\n",
       " 'https://www.gummigoetz.de',\n",
       " 'http://www.suppliersof.com',\n",
       " 'https://www.aikolon.fi',\n",
       " 'http://mikro-technik.com',\n",
       " 'http://de.jointeflons.com',\n",
       " 'https://hbc-system.com',\n",
       " 'http://german.aiflon.com',\n",
       " 'https://www.briskheat.com',\n",
       " 'https://www.wmh-herion.de',\n",
       " 'https://de.industrial-seals.com',\n",
       " 'http://de.plasticptfe.com',\n",
       " 'https://www.sandprofile.de',\n",
       " 'http://de.techoseal.com',\n",
       " 'http://www.minipack.us',\n",
       " 'https://www.polyfluor.nl',\n",
       " 'https://www.miprcorp.com',\n",
       " 'https://www.mn-net.com',\n",
       " 'http://www.atio.cz',\n",
       " 'https://www.zse.de',\n",
       " 'https://www.klinger-awschultze.de',\n",
       " 'https://www.aerchs.com',\n",
       " 'https://www.heckerwerke.de',\n",
       " 'https://www.yachticon.de',\n",
       " 'https://www.ahlstrom-munksjo.com',\n",
       " 'http://de.rilsonindustry.com',\n",
       " 'https://www.jowat.com',\n",
       " 'https://www.bostik.com',\n",
       " 'https://www.hufschmied.net',\n",
       " 'https://www.schreiber-berlin.de',\n",
       " 'https://www.stoeffl.at',\n",
       " 'https://www.reinz-industrial.com',\n",
       " 'https://www.klinger-international.com',\n",
       " 'http://de.foam-silicone.com',\n",
       " 'http://de.chinaomen.com',\n",
       " 'http://www.sweere.net',\n",
       " 'http://www.miac.com.br',\n",
       " 'https://www.h-t-w.at',\n",
       " 'http://poolcorp.info',\n",
       " 'http://www.irizar-sat.com.br',\n",
       " 'http://www.besseges-vtf.co.uk',\n",
       " 'http://www.criscarreira.com',\n",
       " 'https://www.hyspecs.co.nz',\n",
       " 'https://www.kartelllabware.com',\n",
       " 'https://www.millerwelds.com',\n",
       " 'http://www.gre.es',\n",
       " 'https://www.apimex.org']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SITES_LIST = []\n",
    "\n",
    "with open('./site_lists/01_websites.csv', 'r', newline = '') as f:\n",
    "    for site in f.readlines():\n",
    "        SITES_LIST.append(site.strip())\n",
    "\n",
    "SITES_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "direct-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITES_LIST = SITES_LIST[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "billion-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_main(main_url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the URL of the main site, scrapes the text and the links. \n",
    "    site_url: string. url of the desired site.\n",
    "    \"\"\"\n",
    "    \n",
    "    random_header = get_header()\n",
    "    \n",
    "    page = requests.get(site_url, {'header': random_header})\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    page_text = soup.get_text(separator = '\\n', strip=True) \n",
    "       \n",
    "    page_links = get_links(soup)\n",
    "    page_links = filter_links(site_url, page_links)\n",
    "        \n",
    "    return page_text, page_links   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "worse-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(link_url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the URL from one of the link, scrapesa and returns the text. \n",
    "    link_url: string. url of the desired site.\n",
    "    \"\"\"\n",
    "    \n",
    "    random_header = get_header()\n",
    "    \n",
    "      \n",
    "    page = requests.get(link_url, {'header': random_header})\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        \n",
    "    page_text = soup.get_text(separator = '\\n', strip=True) \n",
    "    \n",
    "    print(f'Retrieved text from {link_url}')\n",
    "    \n",
    "    return page_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "delayed-scene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GUMMI-GÖTZ | Hersteller von Gummiformteilen und Dichtungen\\nDonnerstag 21 Januar 2021\\nImpressum\\nAGB\\nDatenschutzerklärung\\nHome\\nProdukte\\nBack\\nGummiformartikel\\nFenster- und Türdichtungen\\nProfile\\nFlachdichtungen\\nSchaumstoffe\\nDicht- und Klebstoffe\\nGummi-Metall- Verbindungen\\nSchläuche\\nDichtungen\\nGummirollen\\nKunststoffe\\nMaterialien\\nÜber uns\\nKontakt\\nBack\\nImpressum\\nAGB\\nDatenschutzerklärung\\nvon Profilen und Teilen aus Gummi\\n& Individuallösungen\\nMaßanfertigungen\\nindividuell abgestimmter Produkte\\nFertigung hochwertiger,\\nHerzlich willkommen\\nGUMMI-GÖTZ – Ihr Spezialist für industrielle Gummiformteile aller Art\\nSeit 2004 schätzen unsere Kunden insbesondere unsere innovativen Lösungen für technisch hochwertige und individuelle Gummiformartikel.\\nNeben einem großen Sortiment an Standardartikeln wie Profilen, Fenster- und Türdichtungen, Schaumstoffen sowie Dicht- und Klebestoffen für den Handwerks- und privaten Bereich finden Sie bei uns vor allem Ansprechpartner für individuelle technische Lösungen und Kleinserien für die industrielle Produktion.\\nBesonders unsere Kunden aus dem Maschinenbau, der Medizin- und Labortechnik, der Automobilindustrie, der Eisenbahntechnik, der Lebensmittelindustrie, der Kommunaltechnik und Bauindustrie schätzen die hohe Produkt- und Servicequalität sowie Zuverlässigkeit unseres mittelständischen Familienunternehmens.\\nWir freuen uns auf Sie und immer wieder neue Herausforderungen in der Entwicklung und Produktion von Prototypen, der Anfertigung von Spezialwerkzeugen (Präzisions-Metallformen) sowie kleinen und mittleren Serien von Gummiformteilen. Kaum ein Bereich in Handwerk und Industrie kommt ohne spezielle Dichtungen, Schläuche und technische Gummiteile aus.\\nSprechen Sie uns gern direkt an: 0049 33 34- 28 33 10, schreiben Sie uns an\\nDiese E-Mail-Adresse ist vor Spambots geschützt! Zur Anzeige muss JavaScript eingeschaltet sein!\\noder besuchen Sie uns direkt im Laden Heegermühler Straße 64 (Haus 36 auf dem Kranbaugelände) in 16225 Eberswalde.\\nWir bieten\\nein umfangreiches Programm aus Gummi und Kunststoff und garantieren überzeugende Ergebnisse - unabhängig von der gewünschten Stückzahl und\\ndem vorgesehenen Einsatzbereich.\\nWir produzieren\\nIhre Gummi-Formartikel aus Präzisions-Metallformen und das auf Wunsch auch\\nin kleinen Stückzahlen.\\nWir fertigen\\nGummi- und Kunststoffartikel\\nauch in Handkonfektion.\\nWir realisieren\\nVersuchsmengen und begleiten das Produkt vom Prototyp bis zur Serie mit unserer individuellen und lösungsorientierten Beratung.\\nWir verarbeiten\\nAlle industrieüblichen Kautschuke\\nund Kunststoffe.\\nWir fertigen und liefern:\\nGummiformartikel\\n+\\n-\\nFenster- und Türdichtungen\\n+\\n-\\nProfile\\n+\\n-\\nFlachdichtungen\\n+\\n-\\nSchaumstoffe\\n+\\n-\\nDicht- und Klebstoffe\\n+\\n-\\nGummi-Metall- Verbindungen\\n+\\n-\\nSchläuche\\n+\\n-\\nDichtungen\\n+\\n-\\nKunststoffe\\n+\\n-\\nGummirollen\\n+\\n-\\nMaterialien\\n+\\n-\\nKontakt\\n×\\nTel. 03334-\\xa028 33 10\\n(Montag-Donnerstag: 08.00 – 16.30 Uhr,\\nFreitag: 08.00 – 12.00 Uhr)\\nTel. 0151- 51 227 188\\n(außerhalb der Geschäftszeiten)\\nE-Mail:\\nDiese E-Mail-Adresse ist vor Spambots geschützt! Zur Anzeige muss JavaScript eingeschaltet sein!\\nMenü\\nHome\\nKontakt\\nÜber uns\\nImpressum\\nAGB\\nDatenschutzerklärung\\nProdukte\\nGummiformartikel\\nFenster- und Türdichtungen\\nProfile\\nFlachdichtungen\\nSchaumstoffe\\nDicht- und Klebstoffe\\nGummi-Metall- Verbindungen\\nSchläuche\\nDichtungen\\nKunststoffe\\nGummirollen\\n©\\n        2021\\n    GUMMI - GÖTZ Henke & Bogdain OHG - Heegermühler Straße 64, Haus 36 - D-16225 Eberswalde'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_site('https://www.gummigoetz.de', getlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "elegant-better",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from main page www.gummigoetz.de written to ./site_contents/www.gummigoetz.de\n",
      "BEGIN PARALLELL\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/dicht-und-klebstoffeRetrieved text from https://www.gummigoetz.de/de/materialien\n",
      "\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/flachdichtungen\n",
      "Retrieved text from https://www.gummigoetz.de/de/kontakt-hinweis/datenschutz\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/dichtungen\n",
      "Retrieved text from https://www.gummigoetz.de/de/kontakt-hinweis/agb\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/schaumstoffe\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/gummi-metall-verbindungen\n",
      "Retrieved text from https://www.gummigoetz.de/de/\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte\n",
      "END PARALLELL\n",
      "BEGIN SERIAL\n",
      "Retrieved text from https://www.gummigoetz.de/de/kontakt-hinweis/datenschutz\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/flachdichtungen\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/dicht-und-klebstoffe\n",
      "Retrieved text from https://www.gummigoetz.de/de/kontakt-hinweis/agb\n",
      "Retrieved text from https://www.gummigoetz.de/de/materialien\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/dichtungen\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/gummi-metall-verbindungen\n",
      "Retrieved text from https://www.gummigoetz.de/de/produkte/schaumstoffe\n",
      "Retrieved text from https://www.gummigoetz.de/de/\n",
      "END SERIAL\n"
     ]
    }
   ],
   "source": [
    "max_links = 10\n",
    "\n",
    "for site in SITES_LIST[4:5]:\n",
    "    \n",
    "    domain = urlparse(site).netloc\n",
    "    \n",
    "    file_name = FILES_DIRECTORY + domain\n",
    "\n",
    "    # get links and text from the main site\n",
    "    text, links_list = scrape_site(site, getlinks=True)\n",
    "    \n",
    "    #write text of the main site\n",
    "    \n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    print(f'Text from main page {domain} written to {file_name}')\n",
    "    \n",
    "    # set text to empty string\n",
    "    text = ''\n",
    "    \n",
    "    start_time_p = time.time()\n",
    "    print('BEGIN PARALLELL')\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(6) as p:\n",
    "            link_text = p.map(scrape_links, links_list[:10])\n",
    "              \n",
    "    \n",
    "    text=link_text\n",
    "    duration_p = time.time() - start_time_p\n",
    "    print('END PARALLELL')\n",
    "    \n",
    "    start_time_s = time.time()\n",
    "    print(\"BEGIN SERIAL\")\n",
    "    text = ''\n",
    "    for link in links_list[:10]:\n",
    "        link_text = scrape_links(link)\n",
    "        text += '\\n' + link_text\n",
    "    duration_s = time.time() - start_time_s\n",
    "    print(\"END SERIAL\")\n",
    "    \"\"\"           \n",
    "    \n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write('\\n'.join(text))\n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "essential-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallell took 2.65s\n",
      "Serial took 12.70s\n"
     ]
    }
   ],
   "source": [
    "print(f'Parallell took {duration_p:.2f}s')\n",
    "print(f'Serial took {duration_s:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "informative-ending",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'duration_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-dd92d7f83402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mduration_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'duration_s' is not defined"
     ]
    }
   ],
   "source": [
    "duration_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "coordinated-cargo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(['a', 'b', 'c' ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "institutional-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-arlington",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
